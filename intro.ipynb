{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc00801",
   "metadata": {},
   "source": [
    "# üöÄ END-TO-END ML PROJECT\n",
    "\n",
    "**(Production-Grade | Docker | CI/CD | AWS | Azure)**\n",
    "\n",
    "\n",
    "## üî∞ PART 0: PROJECT FOUNDATION (VERY IMPORTANT)\n",
    "\n",
    "### 1Ô∏è‚É£ `setup.py` ‚Äì Project Packaging\n",
    "\n",
    "* Converts project into a **Python package**\n",
    "* Enables clean imports across modules\n",
    "* Required for scalable & production-ready ML projects\n",
    "\n",
    "```python\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "setup(\n",
    "    name=\"mlproject\",\n",
    "    version=\"0.0.1\",\n",
    "    packages=find_packages()\n",
    ")\n",
    "```\n",
    "\n",
    "**Interview line:**\n",
    "\n",
    "> ‚ÄúI used `setup.py` to package the ML project and enable modular imports.‚Äù\n",
    "\n",
    "\n",
    "\n",
    "### 2Ô∏è‚É£ `__init__.py`\n",
    "\n",
    "* Marks folders as **Python packages**\n",
    "* Enables structured imports\n",
    "\n",
    "```python\n",
    "from src.components.data_ingestion import DataIngestion\n",
    "```\n",
    "\n",
    "**Interview line:**\n",
    "\n",
    "> ‚Äú`__init__.py` ensures folders behave as importable Python packages.‚Äù\n",
    "\n",
    "\n",
    "\n",
    "### 3Ô∏è‚É£ `src/` Folder Design\n",
    "\n",
    "* Separates **business logic** from deployment files\n",
    "* Prevents circular imports\n",
    "* Industry-standard ML layout\n",
    "\n",
    "\n",
    "### 4Ô∏è‚É£ `logger.py`\n",
    "\n",
    "* Centralized logging (instead of `print`)\n",
    "* Logs pipeline steps, errors, model metrics\n",
    "\n",
    "**Interview line:**\n",
    "\n",
    "> ‚ÄúLogging makes the system debuggable in production.‚Äù\n",
    "\n",
    "\n",
    "\n",
    "### 5Ô∏è‚É£ `exception.py`\n",
    "\n",
    "* Custom exceptions with:\n",
    "\n",
    "  * File name\n",
    "  * Line number\n",
    "  * Meaningful message\n",
    "\n",
    "**Interview line:**\n",
    "\n",
    "> ‚ÄúCustom exceptions improve traceability across pipelines.‚Äù\n",
    "\n",
    "\n",
    "\n",
    "### 6Ô∏è‚É£ `requirements.txt`\n",
    "\n",
    "* Ensures reproducible environments\n",
    "* Used by Docker & CI/CD\n",
    "\n",
    "\n",
    "### 7Ô∏è‚É£ `.gitignore`\n",
    "\n",
    "* Prevents pushing:\n",
    "\n",
    "  * secrets\n",
    "  * models\n",
    "  * cache files\n",
    "\n",
    "\n",
    "\n",
    "## üß© PART 1: PROJECT STRUCTURE\n",
    "\n",
    "```\n",
    "project-root/\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ artifacts/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ model.pkl\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ preprocessor.pkl\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ src/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ components/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_ingestion.py\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_transformation.py\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_trainer.py\n",
    "‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ pipeline/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_pipeline.py\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predict_pipeline.py\n",
    "‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ logger.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ exception.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ utils.py\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ templates/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ index.html\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ home.html\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ application.py\n",
    "‚îú‚îÄ‚îÄ Dockerfile\n",
    "‚îú‚îÄ‚îÄ requirements.txt\n",
    "‚îú‚îÄ‚îÄ setup.py\n",
    "‚îú‚îÄ‚îÄ .github/workflows/main.yml\n",
    "‚îî‚îÄ‚îÄ README.md\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5bc90d",
   "metadata": {},
   "source": [
    "Create New Repository and Sync to Github:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1fc8eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b98f13f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## üß© PART 2: TRAINING PIPELINE\n",
    "\n",
    "### üîπ Data Ingestion\n",
    "\n",
    "* Reads dataset\n",
    "* Splits train/test\n",
    "* Stores raw data\n",
    "\n",
    "### üîπ Data Transformation\n",
    "\n",
    "* Numerical ‚Üí scaling\n",
    "* Categorical ‚Üí encoding\n",
    "* Uses `ColumnTransformer`\n",
    "* Saves `preprocessor.pkl`\n",
    "\n",
    "### üîπ Model Trainer\n",
    "\n",
    "* Trains multiple models:\n",
    "\n",
    "  * Linear Regression\n",
    "  * Decision Tree\n",
    "  * Random Forest\n",
    "  * Gradient Boosting\n",
    "  * KNN\n",
    "* Uses **GridSearchCV**\n",
    "* Selects best model using **R¬≤ score**\n",
    "* Saves `model.pkl`\n",
    "\n",
    "**Artifacts Generated**\n",
    "\n",
    "```\n",
    "model.pkl\n",
    "preprocessor.pkl\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## üß© PART 3: PREDICTION PIPELINE\n",
    "\n",
    "### üîπ CustomData Class\n",
    "\n",
    "* Converts HTML inputs ‚Üí DataFrame\n",
    "\n",
    "### üîπ PredictPipeline\n",
    "\n",
    "* Loads saved model & preprocessor\n",
    "* Applies transformation\n",
    "* Returns prediction\n",
    "\n",
    "### üîπ Flask App (`application.py`)\n",
    "\n",
    "* `/` ‚Üí Home page\n",
    "* `/predictdata` ‚Üí POST request\n",
    "* Displays prediction\n",
    "\n",
    "**Same pipeline works for:**\n",
    "\n",
    "* Web UI\n",
    "* API\n",
    "* Postman\n",
    "\n",
    "\n",
    "## üß© PART 4: DOCKERIZATION\n",
    "\n",
    "### üîπ Dockerfile\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.8-slim-buster\n",
    "WORKDIR /app\n",
    "COPY . /app\n",
    "RUN pip install -r requirements.txt\n",
    "CMD [\"python3\", \"application.py\"]\n",
    "```\n",
    "\n",
    "### üîπ Why Docker?\n",
    "\n",
    "* OS-independent deployment\n",
    "* Same behavior locally & cloud\n",
    "* Easy scaling\n",
    "\n",
    "\n",
    "\n",
    "## üß© PART 5: CI/CD USING GITHUB ACTIONS\n",
    "\n",
    "### üîπ Workflow (`main.yml`)\n",
    "\n",
    "**Triggered on push to `main`**\n",
    "\n",
    "#### Stages:\n",
    "\n",
    "1. **Continuous Integration**\n",
    "\n",
    "   * Code checkout\n",
    "   * Linting / tests\n",
    "2. **Build & Push**\n",
    "\n",
    "   * Build Docker image\n",
    "   * Push to registry\n",
    "3. **Continuous Deployment**\n",
    "\n",
    "   * Pull image\n",
    "   * Deploy automatically\n",
    "\n",
    "\n",
    "## üß© PART 6: AWS DEPLOYMENT (PRIVATE)\n",
    "\n",
    "### üîπ AWS Services\n",
    "\n",
    "* **IAM** ‚Äì Secure access\n",
    "* **ECR** ‚Äì Private Docker registry\n",
    "* **EC2** ‚Äì Application server\n",
    "\n",
    "### üîπ Flow\n",
    "\n",
    "```\n",
    "GitHub ‚Üí GitHub Actions ‚Üí ECR ‚Üí EC2\n",
    "```\n",
    "\n",
    "### üîπ Key Points\n",
    "\n",
    "* Self-hosted GitHub runner on EC2\n",
    "* Port **8080** exposed\n",
    "* Fully automated deployment\n",
    "\n",
    "\n",
    "\n",
    "## üß© PART 7: AZURE DEPLOYMENT\n",
    "\n",
    "### üîπ Azure Services\n",
    "\n",
    "* **Azure Container Registry (ACR)**\n",
    "* **Azure Web App for Containers**\n",
    "\n",
    "### üîπ Flow\n",
    "\n",
    "```\n",
    "GitHub ‚Üí GitHub Actions ‚Üí ACR ‚Üí Azure Web App\n",
    "```\n",
    "\n",
    "### üîπ Highlights\n",
    "\n",
    "* Private Docker image\n",
    "* Continuous deployment enabled\n",
    "* Auto-scaling support\n",
    "\n",
    "---\n",
    "\n",
    "## üß† INTERVIEW QUESTIONS (MOST IMPORTANT)\n",
    "\n",
    "### 1Ô∏è‚É£ Explain your project end-to-end\n",
    "\n",
    "> Built modular ML pipelines, Dockerized the app, automated CI/CD, and deployed on AWS & Azure.\n",
    "\n",
    "\n",
    "\n",
    "### 2Ô∏è‚É£ Why `setup.py`?\n",
    "\n",
    "> To package the project and enable clean modular imports.\n",
    "\n",
    "\n",
    "\n",
    "### 3Ô∏è‚É£ Why separate training & prediction pipelines?\n",
    "\n",
    "> Training is batch-heavy; prediction must be fast and reusable.\n",
    "\n",
    "\n",
    "\n",
    "### 4Ô∏è‚É£ Why save model & preprocessor?\n",
    "\n",
    "> To avoid data leakage and ensure consistent inference.\n",
    "\n",
    "\n",
    "\n",
    "### 5Ô∏è‚É£ Why Docker?\n",
    "\n",
    "> Environment consistency and scalable deployments.\n",
    "\n",
    "\n",
    "\n",
    "### 6Ô∏è‚É£ Docker Hub vs ECR vs ACR?\n",
    "\n",
    "* Docker Hub ‚Üí Public\n",
    "* ECR / ACR ‚Üí Private enterprise registries\n",
    "\n",
    "\n",
    "\n",
    "### 7Ô∏è‚É£ What is CI/CD in your project?\n",
    "\n",
    "> CI validates code, CD builds Docker images and deploys automatically.\n",
    "\n",
    "\n",
    "\n",
    "### 8Ô∏è‚É£ Why self-hosted runner?\n",
    "\n",
    "> To deploy directly to EC2 without manual SSH.\n",
    "\n",
    "\n",
    "\n",
    "### 9Ô∏è‚É£ How would you scale this?\n",
    "\n",
    "> Load balancer, auto-scaling, Kubernetes, ECS / AKS.\n",
    "\n",
    "\n",
    "\n",
    "### üîü How do you monitor in production?\n",
    "\n",
    "> Logs, cloud monitoring, health checks, model drift tracking.\n",
    "\n",
    "\n",
    "\n",
    "## üéØ FINAL ONE-LINE INTERVIEW SUMMARY\n",
    "\n",
    "> ‚ÄúThis is a production-grade ML system with modular pipelines, Dockerized deployment, CI/CD automation, and cloud-native deployment on AWS and Azure.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e38317",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f4ebeb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
